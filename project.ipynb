{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据形状为： (425688, 34)\n",
      "删除重复记录后的数据形状为： (425673, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除重复列后的数据形状： (425673, 34)\n",
      "降维后的数据形状为: (425673, 29)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # 导入 pandas 库\n",
    "\n",
    "data = pd.read_csv('./data/USER_INFO_M.csv', index_col=0, encoding='gbk')  # 读取数据文件\n",
    "print('原始数据形状为：', data.shape)  # 打印原始数据的形状\n",
    "\n",
    "data_drop = pd.DataFrame.drop_duplicates(data, subset=None, keep='first', inplace=False)  # 删除重复的行\n",
    "print('删除重复记录后的数据形状为：', data_drop.shape)  # 打印删除重复行后的数据形状\n",
    "\n",
    "def FeatureEquals(df):  # 定义一个函数用于比较列是否完全相等\n",
    "    dfEquals = pd.DataFrame([], columns=df.columns, index=df.columns)  # 创建一个空的 DataFrame 用于存储比较结果\n",
    "    for i in df.columns:  # 遍历列名\n",
    "        for j in df.columns:  # 再次遍历列名\n",
    "            dfEquals.loc[i, j] = df.loc[:, i].equals(df.loc[:, j])  # 比较两列是否完全相等\n",
    "    return dfEquals  # 返回比较结果的 DataFrame\n",
    "\n",
    "detEquals = FeatureEquals(data_drop)  # 调用函数进行列比较\n",
    "lenDet = detEquals.shape[0]  # 获取比较结果 DataFrame 的行数\n",
    "dupCol = []  # 创建一个空列表用于存储重复的列名\n",
    "for k in range(lenDet):  # 外层循环\n",
    "    for l in range(k + 1, lenDet):  # 内层循环\n",
    "        if detEquals.iloc[k, l] and (detEquals.columns[l] not in dupCol):  # 如果两列相等且列名未在重复列表中\n",
    "            dupCol.append(detEquals.columns[l])  # 将列名添加到重复列表\n",
    "data_drop.drop(dupCol, axis=1, inplace=True)  # 删除重复的列\n",
    "print('删除重复列后的数据形状：', data_drop.shape)  # 打印删除重复列后的数据形状\n",
    "\n",
    "# 数据降维\n",
    "del data_drop['MODEL_NAME']  # 删除指定列\n",
    "del data_drop['AGREE_EXP_DATE']  # 删除指定列\n",
    "del data_drop['CUST_SEX']  # 删除指定列\n",
    "del data_drop['CONSTELLATION_DESC']  # 删除指定列\n",
    "del data_drop['CERT_AGE']  # 删除指定列\n",
    "print('降维后的数据形状为:', data_drop.shape)  # 打印降维后的数据形状\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 每个特征缺失的率为：\n",
      " USER_ID                      0.00023492211157390768%\n",
      "INNET_MONTH                  0.00023492211157390768%\n",
      "IS_AGREE                     0.00023492211157390768%\n",
      "CREDIT_LEVEL                 0.00023492211157390768%\n",
      "VIP_LVL                           37.32325047630458%\n",
      "ACCT_FEE                     0.00023492211157390768%\n",
      "CALL_DURA                    0.00023492211157390768%\n",
      "NO_ROAM_LOCAL_CALL_DURA      0.00023492211157390768%\n",
      "NO_ROAM_GN_LONG_CALL_DURA    0.00023492211157390768%\n",
      "GN_ROAM_CALL_DURA            0.00023492211157390768%\n",
      "CDR_NUM                      0.00023492211157390768%\n",
      "NO_ROAM_CDR_NUM              0.00023492211157390768%\n",
      "NO_ROAM_LOCAL_CDR_NUM        0.00023492211157390768%\n",
      "NO_ROAM_GN_LONG_CDR_NUM      0.00023492211157390768%\n",
      "GN_ROAM_CDR_NUM              0.00023492211157390768%\n",
      "P2P_SMS_CNT_UP               0.00023492211157390768%\n",
      "TOTAL_FLUX                   0.00023492211157390768%\n",
      "LOCAL_FLUX                   0.00023492211157390768%\n",
      "GN_ROAM_FLUX                 0.00023492211157390768%\n",
      "CALL_DAYS                    0.00023492211157390768%\n",
      "CALLING_DAYS                 0.00023492211157390768%\n",
      "CALLED_DAYS                  0.00023492211157390768%\n",
      "CALL_RING                    0.00023492211157390768%\n",
      "CALLING_RING                 0.00023492211157390768%\n",
      "CALLED_RING                  0.00023492211157390768%\n",
      "MANU_NAME                    0.00023492211157390768%\n",
      "OS_DESC                          3.5358127012988843%\n",
      "TERM_TYPE                    0.00023492211157390768%\n",
      "IS_LOST                                       100.0%\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "naRate = (data_drop.isnull().sum() /  # 计算每列的缺失值数量\n",
    "          data_drop.shape[0] * 100).astype('str') + '%'  # 计算缺失值占比，并转换为字符串加上'%'\n",
    "print('data 每个特征缺失的率为：\\n', naRate)  # 打印每个特征的缺失率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理缺失值后数据集的形状为： (425673, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "data_drop['VIP_LVL'] = data_drop['VIP_LVL'].fillna(0)\n",
    "data_drop['OS_DESC'] = data_drop['OS_DESC'].fillna('ANDROID')\n",
    "print('处理缺失值后数据集的形状为：', data_drop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INNET_MONTH</th>\n",
       "      <th>IS_AGREE</th>\n",
       "      <th>CREDIT_LEVEL</th>\n",
       "      <th>VIP_LVL</th>\n",
       "      <th>ACCT_FEE</th>\n",
       "      <th>CALL_DURA</th>\n",
       "      <th>NO_ROAM_LOCAL_CALL_DURA</th>\n",
       "      <th>NO_ROAM_GN_LONG_CALL_DURA</th>\n",
       "      <th>GN_ROAM_CALL_DURA</th>\n",
       "      <th>CDR_NUM</th>\n",
       "      <th>...</th>\n",
       "      <th>LOCAL_FLUX</th>\n",
       "      <th>GN_ROAM_FLUX</th>\n",
       "      <th>CALL_DAYS</th>\n",
       "      <th>CALLING_DAYS</th>\n",
       "      <th>CALLED_DAYS</th>\n",
       "      <th>CALL_RING</th>\n",
       "      <th>CALLING_RING</th>\n",
       "      <th>CALLED_RING</th>\n",
       "      <th>TERM_TYPE</th>\n",
       "      <th>IS_LOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425673.000000</td>\n",
       "      <td>425672.00000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>425672.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.067094</td>\n",
       "      <td>0.514356</td>\n",
       "      <td>66.009343</td>\n",
       "      <td>48.466964</td>\n",
       "      <td>120.95791</td>\n",
       "      <td>21887.222639</td>\n",
       "      <td>12801.741585</td>\n",
       "      <td>3547.150585</td>\n",
       "      <td>5466.478042</td>\n",
       "      <td>187.468687</td>\n",
       "      <td>...</td>\n",
       "      <td>783.449483</td>\n",
       "      <td>333.965681</td>\n",
       "      <td>23.657971</td>\n",
       "      <td>19.540534</td>\n",
       "      <td>20.170655</td>\n",
       "      <td>47.422156</td>\n",
       "      <td>29.442399</td>\n",
       "      <td>31.263628</td>\n",
       "      <td>3.760508</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34.138366</td>\n",
       "      <td>0.499794</td>\n",
       "      <td>0.962192</td>\n",
       "      <td>48.964539</td>\n",
       "      <td>144.68319</td>\n",
       "      <td>24857.761328</td>\n",
       "      <td>17721.210296</td>\n",
       "      <td>6564.093791</td>\n",
       "      <td>13315.597788</td>\n",
       "      <td>212.761225</td>\n",
       "      <td>...</td>\n",
       "      <td>1774.567978</td>\n",
       "      <td>1017.944029</td>\n",
       "      <td>7.807703</td>\n",
       "      <td>8.712807</td>\n",
       "      <td>8.787368</td>\n",
       "      <td>55.587782</td>\n",
       "      <td>41.007111</td>\n",
       "      <td>33.536120</td>\n",
       "      <td>0.470423</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-251.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.00000</td>\n",
       "      <td>6075.750000</td>\n",
       "      <td>1802.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60.157104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>88.08500</td>\n",
       "      <td>14403.000000</td>\n",
       "      <td>6828.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>372.846939</td>\n",
       "      <td>20.848515</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>146.00000</td>\n",
       "      <td>28803.000000</td>\n",
       "      <td>16782.000000</td>\n",
       "      <td>4402.000000</td>\n",
       "      <td>4717.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>926.450099</td>\n",
       "      <td>295.657941</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>248.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>14713.39000</td>\n",
       "      <td>732638.000000</td>\n",
       "      <td>609545.000000</td>\n",
       "      <td>293483.000000</td>\n",
       "      <td>512448.000000</td>\n",
       "      <td>5706.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>481358.912600</td>\n",
       "      <td>74192.874000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4335.000000</td>\n",
       "      <td>4278.000000</td>\n",
       "      <td>1778.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         INNET_MONTH       IS_AGREE   CREDIT_LEVEL        VIP_LVL  \\\n",
       "count  425672.000000  425672.000000  425672.000000  425673.000000   \n",
       "mean       34.067094       0.514356      66.009343      48.466964   \n",
       "std        34.138366       0.499794       0.962192      48.964539   \n",
       "min      -251.000000       0.000000       0.000000       0.000000   \n",
       "25%         9.000000       0.000000      65.000000       0.000000   \n",
       "50%        24.000000       1.000000      66.000000       4.000000   \n",
       "75%        48.000000       1.000000      67.000000      99.000000   \n",
       "max       248.000000       1.000000      67.000000      99.000000   \n",
       "\n",
       "           ACCT_FEE      CALL_DURA  NO_ROAM_LOCAL_CALL_DURA  \\\n",
       "count  425672.00000  425672.000000            425672.000000   \n",
       "mean      120.95791   21887.222639             12801.741585   \n",
       "std       144.68319   24857.761328             17721.210296   \n",
       "min         0.01000       1.000000                 0.000000   \n",
       "25%        56.00000    6075.750000              1802.000000   \n",
       "50%        88.08500   14403.000000              6828.000000   \n",
       "75%       146.00000   28803.000000             16782.000000   \n",
       "max     14713.39000  732638.000000            609545.000000   \n",
       "\n",
       "       NO_ROAM_GN_LONG_CALL_DURA  GN_ROAM_CALL_DURA        CDR_NUM  ...  \\\n",
       "count              425672.000000      425672.000000  425672.000000  ...   \n",
       "mean                 3547.150585        5466.478042     187.468687  ...   \n",
       "std                  6564.093791       13315.597788     212.761225  ...   \n",
       "min                     0.000000           0.000000       1.000000  ...   \n",
       "25%                     0.000000           0.000000      58.000000  ...   \n",
       "50%                   995.000000         310.000000     124.000000  ...   \n",
       "75%                  4402.000000        4717.000000     239.000000  ...   \n",
       "max                293483.000000      512448.000000    5706.000000  ...   \n",
       "\n",
       "          LOCAL_FLUX   GN_ROAM_FLUX      CALL_DAYS   CALLING_DAYS  \\\n",
       "count  425672.000000  425672.000000  425672.000000  425672.000000   \n",
       "mean      783.449483     333.965681      23.657971      19.540534   \n",
       "std      1774.567978    1017.944029       7.807703       8.712807   \n",
       "min         0.000000       0.000000       1.000000       0.000000   \n",
       "25%        60.157104       0.000000      20.000000      13.000000   \n",
       "50%       372.846939      20.848515      27.000000      21.000000   \n",
       "75%       926.450099     295.657941      29.000000      27.000000   \n",
       "max    481358.912600   74192.874000      31.000000      31.000000   \n",
       "\n",
       "         CALLED_DAYS      CALL_RING   CALLING_RING    CALLED_RING  \\\n",
       "count  425672.000000  425672.000000  425672.000000  425672.000000   \n",
       "mean       20.170655      47.422156      29.442399      31.263628   \n",
       "std         8.787368      55.587782      41.007111      33.536120   \n",
       "min         0.000000       1.000000       0.000000       0.000000   \n",
       "25%        14.000000      17.000000      10.000000      10.000000   \n",
       "50%        22.000000      32.000000      19.000000      22.000000   \n",
       "75%        28.000000      61.000000      36.000000      41.000000   \n",
       "max        31.000000    4335.000000    4278.000000    1778.000000   \n",
       "\n",
       "           TERM_TYPE  IS_LOST  \n",
       "count  425672.000000      0.0  \n",
       "mean        3.760508      NaN  \n",
       "std         0.470423      NaN  \n",
       "min         2.000000      NaN  \n",
       "25%         4.000000      NaN  \n",
       "50%         4.000000      NaN  \n",
       "75%         4.000000      NaN  \n",
       "max         4.000000      NaN  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_drop.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理异常值后数据集的形状为： (425671, 29)\n"
     ]
    }
   ],
   "source": [
    "# 删除异常数据\n",
    "data_drop = data_drop[data_drop['INNET_MONTH'] >= 0]\n",
    "data_drop = data_drop[data_drop['ACCT_FEE'] < 400000]\n",
    "print('处理异常值后数据集的形状为：', data_drop.shape)\n",
    "data_drop.to_csv('./data/data_drop.csv', index=True, header='infer', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_group的形状为: (299823, 42)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_drop = pd.read_csv('./data/data_drop.csv', encoding='utf8')\n",
    "# 按照\"USER_ID\"对数据进行分组，并对指定列计算中位数和方差\n",
    "data_group = data_drop.groupby(\"USER_ID\").agg({\n",
    "        'ACCT_FEE': [np.median, np.var],\\\n",
    "        'CALL_DURA': [np.median, np.var], 'CDR_NUM': [np.median, np.var],\\\n",
    "                  'NO_ROAM_LOCAL_CALL_DURA': [np.median, np.var],\\\n",
    "                  'NO_ROAM_LOCAL_CDR_NUM': [np.median, np.var],\\\n",
    "                  'NO_ROAM_GN_LONG_CALL_DURA': [np.median, np.var],\\\n",
    "                  'NO_ROAM_GN_LONG_CDR_NUM': [np.median, np.var],\\\n",
    "                  'GN_ROAM_CALL_DURA': [np.median, np.var], \\\n",
    "                  'GN_ROAM_CDR_NUM': [np.median, np.var], \\\n",
    "                  'NO_ROAM_CDR_NUM': [np.median, np.var],\\\n",
    "                  'P2P_SMS_CNT_UP': [np.median, np.var],\n",
    "                  'TOTAL_FLUX': [np.median, np.var], \\\n",
    "                  'LOCAL_FLUX': [np.median, np.var], \\\n",
    "                  'GN_ROAM_FLUX': [np.median, np.var],\\\n",
    "                  'CALL_DAYS': [np.median, np.var], \\\n",
    "                  'CALLING_DAYS': [np.median, np.var],\\\n",
    "                  'CALLED_DAYS': [np.median, np.var],\\\n",
    "                  'CALL_RING': [np.median, np.var],\\\n",
    "                  'CALLING_RING': [np.median, np.var],\\\n",
    "                  'CALLED_RING': [np.median, np.var],\\\n",
    "                  'INNET_MONTH': [np.median, np.var], })\n",
    "\n",
    "print('data_group的形状为:', data_group.shape)  # 打印数据组的形状\n",
    "# 重命名列名\n",
    "data_group.columns = ['ACCT_FEE_median', 'ACCT_FEE_var', 'CALL_DURA_median', \n",
    "                      'CALL_DURA_var', 'CDR_NUM_median', 'CDR_NUM_var', \n",
    "                      'NO_ROAM_LOCAL_CALL_DURA_median', \n",
    "                      'NO_ROAM_LOCAL_CALL_DURA_var', \n",
    "                      'NO_ROAM_LOCAL_CDR_NUM_median', \n",
    "                      'NO_ROAM_LOCAL_CDR_NUM_var', \n",
    "                      'NO_ROAM_GN_LONG_CALL_DURA_median', \n",
    "                      'NO_ROAM_GN_LONG_CALL_DURA_var', \n",
    "                      'NO_ROAM_GN_LONG_CDR_NUM_median', \n",
    "                      'NO_ROAM_GN_LONG_CDR_NUM_var', \n",
    "                      'GN_ROAM_CALL_DURA_median', \n",
    "                      'GN_ROAM_CALL_DURA_var', \n",
    "                      'GN_ROAM_CDR_NUM_median', \n",
    "                      'GN_ROAM_CDR_NUM_var', \n",
    "                      'NO_ROAM_CDR_NUM_median', \n",
    "                      'NO_ROAM_CDR_NUM_var', \n",
    "                      'P2P_SMS_CNT_UP_median', 'P2P_SMS_CNT_UP_var', \n",
    "                      'TOTAL_FLUX_median', 'TOTAL_FLUX_var', \n",
    "                      'LOCAL_FLUX_median', 'LOCAL_FLUX_var', \n",
    "                      'GN_ROAM_FLUX_median', 'GN_ROAM_FLUX_var', \n",
    "                      'CALL_DAYS_median', 'CALL_DAYS_var', \n",
    "                      'CALLING_DAYS_median', 'CALLING_DAYS_var', \n",
    "                      'CALLED_DAYS_median', 'CALLED_DAYS_var', \n",
    "                      'CALL_RING_median', 'CALL_RING_var', \n",
    "                      'CALLING_RING_median', 'CALLING_RING_var', \n",
    "                      'CALLED_RING_median', 'CALLED_RING_var', \n",
    "                      'INNET_MONTH_median', 'INNET_MONTH_var']\n",
    "# # 将处理后的数据保存到 CSV 文件\n",
    "data_group.to_csv('./data/data_group.csv', index=True, header='infer', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_agree的形状为: (299823,)\n",
      "USER_ID\n",
      "U3114031824148707    0\n",
      "U3114031824148874    0\n",
      "U3114031824148975    0\n",
      "U3114031824149138    0\n",
      "U3114031824149150    0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 将每个用户三个月的合约是否有效，合并为一条记录\n",
    "# 定义合并合约有效记录函数\n",
    "def fun1(data):\n",
    "    \"\"\"\n",
    "    该函数用于处理每个用户三个月的合约是否有效数据\n",
    "    参数:     data (DataFrame): 包含用户合约是否有效信息的数据\n",
    "    返回:     处理后的结果，根据不同条件返回不同值\n",
    "    \"\"\"\n",
    "    if data.shape[0]!= 3:  # 如果数据行数不为 3\n",
    "        return 0\n",
    "    elif sum(data.iloc[:, 1] == 1) == 3:  # 如果三个月的合约都有效\n",
    "        return 1.5\n",
    "    else:  # 其他情况\n",
    "        return data.iloc[-1, 1] - data.iloc[:2, 1].mean()\n",
    "\n",
    "# 对名为data_drop的数据框进行操作，并生成一个新的数据框data_agree\n",
    "data_agree = data_drop[[\"USER_ID\",\"IS_AGREE\"]].groupby(\"USER_ID\").apply(lambda x: fun1(x))\n",
    "# 这里按照\"USER_ID\"对数据进行分组，并应用 fun1 函数进行处理，结果存储在 data_agree 中\n",
    "print('data_agree的形状为:', data_agree.shape)\n",
    "print(data_agree.head(),'\\n')\n",
    "data_agree.to_csv('./data/data_agree.csv', index=True, header='infer', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_vip的形状为: (299823,)\n",
      "USER_ID\n",
      "U3114031824148707    0\n",
      "U3114031824148874    0\n",
      "U3114031824148975    0\n",
      "U3114031824149138    0\n",
      "U3114031824149150    0\n",
      "dtype: int64 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 将每个用户三个月的 VIP 等级合并为一条记录\n",
    "def fun2(data):\n",
    "    \"\"\"\n",
    "    该函数用于处理每个用户三个月的 VIP 等级数据\n",
    "    参数:     data (DataFrame): 包含用户 VIP 等级信息的数据\n",
    "    返回:     处理后的结果，根据不同条件返回不同值\n",
    "    \"\"\"\n",
    "    if data.shape[0]!= 3:  # 如果数据行数不为 3\n",
    "        return 0\n",
    "    elif (data.iloc[0, 1] == data.iloc[1, 1]) & (data.iloc[0, 1] == data.iloc[2, 1]):  # 如果三个月的 VIP 等级相同\n",
    "        return data.iloc[2, 1]\n",
    "    else:  # 其他情况\n",
    "        return data.iloc[2, 1] - data.iloc[:2, 1].mean()\n",
    "\n",
    "data_vip = data_drop[['USER_ID','VIP_LVL']].groupby('USER_ID').apply(lambda x: fun2(x))\n",
    "# 这里按照\"USER_ID\"对数据进行分组，并应用 fun2 函数进行处理，结果存储在 data_vip 中\n",
    "print('data_vip的形状为:', data_vip.shape)\n",
    "print(data_vip.head(),'\\n\\n')\n",
    "data_vip.to_csv('./data/data_vip.csv', index=True, header='infer', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_credit的形状为: (299823, 1)\n",
      "                   CREDIT_LEVEL\n",
      "USER_ID                        \n",
      "U3114031824148707          67.0\n",
      "U3114031824148874          65.0\n",
      "U3114031824148975          65.0\n",
      "U3114031824149138          65.0\n",
      "U3114031824149150          65.0\n"
     ]
    }
   ],
   "source": [
    "# 取每个用户三个月信用等级的平均数作为一行记录\n",
    "data_credit = data_drop.groupby('USER_ID').agg({'CREDIT_LEVEL': np.mean, })\n",
    "data_credit.iloc[:10]\n",
    "print('data_credit的形状为:', data_credit.shape)\n",
    "print(data_credit.head())\n",
    "data_credit.to_csv('./data/data_credit.csv', index=True, header='infer', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简化手机品牌\n",
    "string = ['苹果', '小米', '华为', '三星', '诺基亚', '联想', 'LG']\n",
    "\n",
    "def Replace(x=None, string=string):\n",
    "    if x not in string:\n",
    "        x = '其他'\n",
    "    return x\n",
    "\n",
    "# 每个ID的手机品牌只取第一个月的\n",
    "data_str = data_drop.groupby(\"USER_ID\").apply(lambda x: x.iloc[0])\n",
    "data_manu = data_str['MANU_NAME'].apply(Replace)\n",
    "print('data_manu的形状为:', data_manu.shape)\n",
    "print(data_manu.head())\n",
    "\n",
    "# 简化操作系统\n",
    "# 每个ID的手机操作系统也只取第一个月的\n",
    "data_id = data_drop.groupby(\"USER_ID\").apply(lambda x: x.iloc[0])\n",
    "data_os = data_id[\"OS_DESC\"].str.extract(\"([A-Z]+)\")  # 保留所有的字母\n",
    "print('data_os的形状为:', data_os.shape)\n",
    "print(data_os.head())\n",
    "data_manu.to_csv('./data/data_manu.csv', index=True, header='infer', encoding='utf8')\n",
    "data_os.to_csv('./data/data_os.csv', index=True, header='infer', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "独热编码后的手机品牌的形状： (299968, 8)\n",
      "                   MANU_NAME_LG  MANU_NAME_三星  MANU_NAME_其他  MANU_NAME_华为  \\\n",
      "USER_ID                                                                     \n",
      "U3114031824148707             0             0             0             0   \n",
      "U3114031824148874             0             0             0             0   \n",
      "U3114031824148975             0             0             0             0   \n",
      "U3114031824149138             0             0             0             0   \n",
      "U3114031824149150             0             1             0             0   \n",
      "\n",
      "                   MANU_NAME_小米  MANU_NAME_联想  MANU_NAME_苹果  MANU_NAME_诺基亚  \n",
      "USER_ID                                                                     \n",
      "U3114031824148707             0             0             1              0  \n",
      "U3114031824148874             0             0             1              0  \n",
      "U3114031824148975             0             0             1              0  \n",
      "U3114031824149138             0             0             1              0  \n",
      "U3114031824149150             0             0             0              0  \n",
      "独热编码后的操作系统的形状： (299968, 7)\n",
      "                   0_ANDROID  0_BADA  0_BB  0_BLACKBERRY  0_IOS  0_LINUX  \\\n",
      "USER_ID                                                                    \n",
      "U3114031824148707          0       0     0             0      1        0   \n",
      "U3114031824148874          0       0     0             0      1        0   \n",
      "U3114031824148975          0       0     0             0      1        0   \n",
      "U3114031824149138          0       0     0             0      1        0   \n",
      "U3114031824149150          1       0     0             0      0        0   \n",
      "\n",
      "                   0_WINDOWS  \n",
      "USER_ID                       \n",
      "U3114031824148707          0  \n",
      "U3114031824148874          0  \n",
      "U3114031824148975          0  \n",
      "U3114031824149138          0  \n",
      "U3114031824149150          0   \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 手机品牌独热编码\n",
    "import pandas as pd  # 导入 pandas 库\n",
    "\n",
    "data_manu = pd.read_csv('./data/data_manu.csv', encoding='utf8')  # 读取手机品牌数据文件\n",
    "data_manu.index = data_manu.iloc[:, 0]  # 设置索引\n",
    "data_manu = data_manu.drop(columns='USER_ID')  # 删除'USER_ID'列\n",
    "\n",
    "data_os = pd.read_csv('./data/data_os.csv', encoding='utf8')  # 读取操作系统数据文件\n",
    "data_os.index = data_os.iloc[:, 0]  # 设置索引\n",
    "data_os = data_os.drop(columns='USER_ID')  # 删除'USER_ID'列\n",
    "\n",
    "data_drop = pd.read_csv('./data/data_drop.csv', encoding='utf8')  # 读取其他相关数据文件\n",
    "\n",
    "data_group = pd.read_csv('./data/data_group.csv', encoding='utf8')  # 读取分组数据文件\n",
    "data_group.index = data_group.iloc[:, 0]  # 设置索引\n",
    "data_group = data_group.drop(columns='USER_ID')  # 删除'USER_ID'列\n",
    "\n",
    "data_agree = pd.read_csv('./data/data_agree.csv', encoding='utf8')  # 读取同意相关数据文件\n",
    "data_agree.index = data_agree.iloc[:, 0]  # 设置索引\n",
    "data_agree = data_agree.drop(columns='USER_ID')  # 删除'USER_ID'列\n",
    "\n",
    "data_credit = pd.read_csv('./data/data_credit.csv', encoding='utf8')  # 读取信用数据文件\n",
    "data_credit.index = data_credit.iloc[:, 0]  # 设置索引\n",
    "data_credit = data_credit.drop(columns='USER_ID')  # 删除'USER_ID'列\n",
    "\n",
    "data_vip = pd.read_csv('./data/data_vip.csv', encoding='utf8')  # 读取 VIP 数据文件\n",
    "data_vip.index = data_vip.iloc[:, 0]  # 设置索引\n",
    "data_vip = data_vip.drop(columns='USER_ID')  # 删除'USER_ID'列\n",
    "\n",
    "data_manu = pd.get_dummies(data_manu)  # 对手机品牌数据进行独热编码\n",
    "print('独热编码后的手机品牌的形状：', data_manu.shape)  # 打印形状\n",
    "print(data_manu.head())  # 打印前几行数据\n",
    "data_manu.to_csv('./data/data_manu.csv', encoding='utf8')  # 保存编码后的数据\n",
    "\n",
    "# 操作系统独热编码\n",
    "data_os = pd.get_dummies(data_os)  # 对操作系统数据进行独热编码\n",
    "print('独热编码后的操作系统的形状：', data_os.shape)  # 打印形状\n",
    "print(data_os.head(),'\\n\\n')  # 打印前几行数据\n",
    "data_os.to_csv('./data/data_os.csv', encoding='utf8')  # 保存编码后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_drop的形状： (899901, 30)\n",
      " data_group的形状： (299967, 42)\n",
      " data_agree的形状： (299967, 1)\n",
      " data_vip的形状： (299967, 1)\n",
      " data_credit的形状： (299967, 1)\n",
      " data_manu的形状： (299968, 8)\n",
      " data_os的形状： (299968, 7) \n",
      "\n",
      "\n",
      "合并后数据集的形状为: (299968, 60)\n",
      "                   ACCT_FEE_median  ACCT_FEE_var  CALL_DURA_median  \\\n",
      "U3114031824148707             76.0     27.907500           11901.0   \n",
      "U3114031824148874            260.3   2889.998633           22991.0   \n",
      "U3114031824148975            166.0      0.003333           18972.0   \n",
      "U3114031824149138            146.2   2150.297500           42921.0   \n",
      "U3114031824149150             77.3     48.823333            1206.0   \n",
      "\n",
      "                   CALL_DURA_var  CDR_NUM_median   CDR_NUM_var  \\\n",
      "U3114031824148707   1.640320e+07           183.0  11849.333333   \n",
      "U3114031824148874   2.862449e+07           373.0   6857.333333   \n",
      "U3114031824148975   4.498497e+07           184.0   1849.333333   \n",
      "U3114031824149138   3.123659e+07           217.0    964.000000   \n",
      "U3114031824149150   1.721161e+06            12.0   1240.333333   \n",
      "\n",
      "                   NO_ROAM_LOCAL_CALL_DURA_median  \\\n",
      "U3114031824148707                             0.0   \n",
      "U3114031824148874                         19852.0   \n",
      "U3114031824148975                          3545.0   \n",
      "U3114031824149138                          8888.0   \n",
      "U3114031824149150                          1206.0   \n",
      "\n",
      "                   NO_ROAM_LOCAL_CALL_DURA_var  NO_ROAM_LOCAL_CDR_NUM_median  \\\n",
      "U3114031824148707                 0.000000e+00                           0.0   \n",
      "U3114031824148874                 4.083325e+07                         343.0   \n",
      "U3114031824148975                 1.003213e+08                          90.0   \n",
      "U3114031824149138                 1.100377e+08                          55.0   \n",
      "U3114031824149150                 1.293929e+06                          12.0   \n",
      "\n",
      "                   NO_ROAM_LOCAL_CDR_NUM_var  ...  联想  苹果  诺基亚  0_ANDROID  \\\n",
      "U3114031824148707                   0.000000  ...   0   1    0          0   \n",
      "U3114031824148874                7372.000000  ...   0   1    0          0   \n",
      "U3114031824148975                2602.333333  ...   0   1    0          0   \n",
      "U3114031824149138                5516.333333  ...   0   1    0          0   \n",
      "U3114031824149150                 892.000000  ...   0   0    0          1   \n",
      "\n",
      "                   0_BADA  0_BB  0_BLACKBERRY  0_IOS  0_LINUX  0_WINDOWS  \n",
      "U3114031824148707       0     0             0      1        0          0  \n",
      "U3114031824148874       0     0             0      1        0          0  \n",
      "U3114031824148975       0     0             0      1        0          0  \n",
      "U3114031824149138       0     0             0      1        0          0  \n",
      "U3114031824149150       0     0             0      0        0          0  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "print('data_drop的形状：', data_drop.shape)\n",
    "print(' data_group的形状：', data_group.shape)\n",
    "print(' data_agree的形状：', data_agree.shape)\n",
    "print(' data_vip的形状：', data_vip.shape)\n",
    "print(' data_credit的形状：', data_credit.shape)\n",
    "print(' data_manu的形状：', data_manu.shape)\n",
    "print(' data_os的形状：', data_os.shape,'\\n\\n')\n",
    "\n",
    "import pandas as pd  # 导入 pandas 库\n",
    "\n",
    "# 将多个数据集沿列方向合并\n",
    "data_preprocessed = pd.concat([data_group, data_agree, data_vip, data_credit,data_manu, data_os, ], axis=1)\n",
    "# 打印合并后数据集的形状\n",
    "print('合并后数据集的形状为:', data_preprocessed.shape)\n",
    "\n",
    "# 为合并后的数据集列重命名\n",
    "data_preprocessed.columns = ['ACCT_FEE_median', 'ACCT_FEE_var',\n",
    "                             'CALL_DURA_median', 'CALL_DURA_var',\n",
    "                             'CDR_NUM_median', 'CDR_NUM_var',\n",
    "                             'NO_ROAM_LOCAL_CALL_DURA_median',\n",
    "                             'NO_ROAM_LOCAL_CALL_DURA_var',\n",
    "                             'NO_ROAM_LOCAL_CDR_NUM_median',\n",
    "                             'NO_ROAM_LOCAL_CDR_NUM_var',\n",
    "                             'NO_ROAM_GN_LONG_CALL_DURA_median',\n",
    "                             'NO_ROAM_GN_LONG_CALL_DURA_var',\n",
    "                             'NO_ROAM_GN_LONG_CDR_NUM_median',\n",
    "                             'NO_ROAM_GN_LONG_CDR_NUM_var',\n",
    "                             'GN_ROAM_CALL_DURA_median',\n",
    "                             'GN_ROAM_CALL_DURA_var',\n",
    "                             'GN_ROAM_CDR_NUM_median',\n",
    "                             'GN_ROAM_CDR_NUM_var',\n",
    "                             'NO_ROAM_CDR_NUM_median',\n",
    "                             'NO_ROAM_CDR_NUM_var',\n",
    "                             'P2P_SMS_CNT_UP_median',\n",
    "                             'P2P_SMS_CNT_UP_var',\n",
    "                             'TOTAL_FLUX_median', 'TOTAL_FLUX_var',\n",
    "                             'LOCAL_FLUX_median', 'LOCAL_FLUX_var',\n",
    "                             'GN_ROAM_FLUX_median', 'GN_ROAM_FLUX_var',\n",
    "                             'CALL_DAYS_median', 'CALL_DAYS_var',\n",
    "                             'CALLING_DAYS_median', 'CALLING_DAYS_var',\n",
    "                             'CALLED_DAYS_median', 'CALLED_DAYS_var',\n",
    "                             'CALL_RING_median', 'CALL_RING_var',\n",
    "                             'CALLING_RING_median', 'CALLING_RING_var',\n",
    "                             'CALLED_RING_median', 'CALLED_RING_var',\n",
    "                             'INNET_MONTH_median', 'INNET_MONTH_var',\n",
    "                             'IS_AGREE', 'VIP_LVL', 'CREDIT_LEVEL',\n",
    "                             'LG', '三星', '其他', '华为', '小米',\n",
    "                             '联想', '苹果', '诺基亚',\n",
    "                             '0_ANDROID', '0_BADA', '0_BB', '0_BLACKBERRY',\n",
    "                             '0_IOS', '0_LINUX', '0_WINDOWS']\n",
    "# 打印合并后数据集的前几行\n",
    "print(data_preprocessed.head())\n",
    "# 将合并后的数据集保存为 CSV 文件\n",
    "data_preprocessed.to_csv('./data/data_preprocessed.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "201603",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 201603",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6783/829048507.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdata_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_drop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'USER_ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'IS_LOST'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 提取特定列作为目标变量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdata_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"USER_ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 筛选出 USER_ID 在 data_preprocessed 索引中的数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdata_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m201603\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 筛选出三月份的数据并去除重复项\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'目标变量数据集的形状为:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 打印目标变量数据集的形状\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3491\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3493\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 201603"
     ]
    }
   ],
   "source": [
    "# 导入所需的库\n",
    "import pandas as pd  # 用于数据处理和分析\n",
    "from sklearn.model_selection import train_test_split  # 用于划分数据集\n",
    "from sklearn.preprocessing import StandardScaler  # 用于数据标准化\n",
    "from sklearn.neural_network import MLPClassifier  # 多层感知机分类器\n",
    "from sklearn.metrics import classification_report  # 用于生成分类报告\n",
    "\n",
    "# 导入数据\n",
    "data_drop = pd.read_csv('./data/data_drop.csv', encoding='utf-8', index_col=0)  # 读取 data_drop.csv 数据文件\n",
    "data_preprocessed = pd.read_csv('./data/data_preprocessed.csv', encoding='utf-8', index_col=0)  # 读取 data_preprocessed.csv 数据文件\n",
    "\n",
    "# 取 data_preprocessed 作为输入，取 data_drop 中三月份的数据的目标变量作为输出\n",
    "data_target = data_drop.loc[:, ['USER_ID', 'IS_LOST']]  # 提取特定列作为目标变量\n",
    "data_target = data_target.loc[data_target[\"USER_ID\"].isin(data_preprocessed.index)]  # 筛选出 USER_ID 在 data_preprocessed 索引中的数据\n",
    "data_target = data_target.loc[201603].drop_duplicates()  # 筛选出三月份的数据并去除重复项\n",
    "print('目标变量数据集的形状为:', data_target.shape)  # 打印目标变量数据集的形状\n",
    "\n",
    "# 划分数据集\n",
    "x = data_preprocessed  # 输入特征数据\n",
    "y = data_target  # 目标变量\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y['IS_LOST'], test_size=0.2, random_state=42)  # 以 8:2 的比例划分训练集和测试集，设置随机数种子为 42\n",
    "print('训练集数据的形状为：', x_train.shape)  # 打印训练集数据的形状\n",
    "print('训练集标签的形状为：', y_train.shape)  # 打印训练集标签的形状\n",
    "print('测试集数据的形状为：', x_test.shape)  # 打印测试集数据的形状\n",
    "print('测试集标签的形状为：', y_test.shape)  # 打印测试集标签的形状\n",
    "\n",
    "# 数据标准化\n",
    "stdScaler = StandardScaler().fit(x_train)  # 在训练集上拟合标准化器\n",
    "x_stdtrain = stdScaler.transform(x_train)  # 对训练集数据进行标准化\n",
    "x_stdtest = stdScaler.transform(x_test)  # 对测试集数据进行标准化\n",
    "print('标准化后的 x_stdtrain:\\n', x_stdtrain)  # 打印标准化后的训练集数据\n",
    "print('标准化后的 x_stdtest:\\n', x_stdtest)  # 打印标准化后的测试集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "bpnn = MLPClassifier(hidden_layer_sizes=(17, 10),\\\n",
    "                     max_iter=200, solver='lbfgs', random_state=50)\n",
    "bpnn.fit(x_stdtrain, y_train)\n",
    "print('构建的模型为:\\n', bpnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "y_pre = bpnn.predict(x_stdtest)\n",
    "print('多层感知器预测结果评价报告：\\n', classification_report(y_test, y_pre))\n",
    "\n",
    "# %matplotlib inline\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制ROC曲线图\n",
    "plt.rcParams['font.sans-serif'] = 'SimHei'  # 显示中文\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 显示负号\n",
    "fpr, tpr, thresholds = roc_curve(y_pre, y_test)  # 求出TPR和FPR\n",
    "plt.figure(figsize=(6, 4))  # 创建画布\n",
    "plt.plot(fpr, tpr)  # 绘制曲线\n",
    "plt.title('用户流失模型的ROC曲线')  # 标题\n",
    "plt.xlabel('FPR')  # x轴标签\n",
    "plt.ylabel('TPR')  # y轴标签\n",
    "plt.show()  # 显示图形\n",
    "plt.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('python35-paddle120-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09f0dbf7b1569c1ab842ae2f41770fe6aa1b54326d081112fa5944b99abb5899"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
